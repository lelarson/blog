{
  
    
        "post0": {
            "title": "Deep Learning For Coders Ch1 Questionairre",
            "content": "chapter 1 . My responses to the questionnaire in Chapter 1 of Deep Learning for Coders with fastai and PyTorch by Jeremy Howard and Sylvain Gugger. . Do you need these for deep learning? Lots of math? Nope | Lots of data? Not necessarily | Lots of expensive computers? No | a PhD? Definitely not | . | Name five areas where deep learning is now the best in the world. 1. Computer vision 2. Robotics 3. Recommendation systems 4. DNA sequencing 5. Board games . | What was the name of the first device that was based on the principle of the artificial neuron? Mark 1 Perceptron Frank Rosenblatt | Simulated on an IBM 704 computer at Cornell in 1957 p. 193 in Pattern Recognition and Machine Learning by Christopher M. Bishop | . | . | Builds off the first documented mathematical model of an artificial neuron, the Threshold Logic Unit proposed by McCulloch and Pitts in 1943 The Mark 1 Perceptron built off this by : Allowing any real inputs instead of binary values | Weighting different inputs differently | Adding a learning function | . | From presentation by Dave Beeman at the University of Colorado | . | . | Based on the book of the same name, what are the requirements for Parallel Distributed Processing (PDP)? processing units | a state of activation | an output function for each unit | a pattern of connectivity among units | a propagation rule for propagating activities through the network | an activation rule whereby patterns of connectivity are modified by experience | environment in which the system will operate | | What were the two theoretical misunderstandings that held back the field of neural networks? In 1969, a paper titled “Perceptrons” by Marvin Minsky and Seymour Papert was largely misinterpreted as showing that neural networks could only learn solutions to linear separable problems. In reality, the authors proved that such limitations only exist in the case of single-layer networks, like the Mark 1 Perceptron. However, they incorrectly speculated that this limitation might extend to more complex network models, and - despite being speculation - this appears to be the primary takeaway by the ML community given the subsequent decline in research funding for neural computing. Subsequently, the first AI winter began… | …only for neural networks to regain attention in the 1980s, when models with more than one layer were being explored. While it is possible to approximate any mathematical function using two layers of artificial neurons - and it was demonstrated that adding additional layers improved performance - this insight was not acknowledged, and these networks were too big and too slow to be of practical use anyway. Subsequently, the second AI winter began. | | What is a GPU? GPU = graphics processing unit (or graphics card) | Whereas a CPU is good for sequential processing, a GPU is better for simultaneously performing many mathematical calculations, such as those needed for deep learning. Because of this, the use of a GPU can dramatically speed up the training of a neural network model. | . | Open a notebook and execute a cell containing “1+1”. What happens? We get 2. | . | Another interactive exercise | … And another . | Why is it hard to use a traditional computer program to recognize images in a photo? Like a baby who has not yet learned how to name the things it sees, a traditional computer program doesn’t know what it doesn’t know. There needs to be a process for it to identify different clues that could lead it to classify whatever its looking at as one thing or another. While a human child will have many different influences to help it learn efficient processes over time, a traditional computer program would need an explicit set of rules so it would know precisely what to look for. | This is where machine learning comes into play. Instead of having inputs and a set of rules to get a desired results, we instead have our inputs and a set of ideal outputs, and the algorithm figures out the set of rules for us. | . | What did Samuel mean by “weight assignment”? By “weights” he means variables where “weight assignment” refers to the current values of those variables Because they will affect the program, they are in a sense another input using Samuel’s usage | . | . | What term do we normally use in deep learning for what Samuel called “weights”? parameters | Nowadays, “weights” refers to a particular type of model parameter two types of neural network parameters are weights and biases | . | . | Draw a picture that summarizes Samuel’s view of a machine learning model. . | Why is it hard to understand why a deep learning model makes a particular prediction? referring to the interpretability of the model | Deep learning models are specifically hard to understand in part due to their “deep” nature. Unlike a linear regression model, where we can understand which variables are more or less important by their weights, deep neural networks have upwards of thousands of layers and, currently, there aren’t many great ways to determine which factors are most important. However, there is progress in this area. For example, this chapter shows that we can analyze the sets of weights of a neural network model and determine what kind of features activate the neurons. More specifically, when applying CNNs to images, we can also see which parts of the images activate the model. | . | . | What is the name of the theorem that shows that a neural network can solve any mathematical problem to any level of accuracy? universal approximation theorem due to imperfect data and the limitations of time and computer hardware, it is impossible to practically train a model to perfectly approximate all functions | but we can get damn close | . | . | What do you need in order to train a deep learning model? data / measurements for many use cases, labels for those data | . | an architecture for the network | a loss function to measure performance | a mechanism for updating the weights | . | How could a feedback loop impact the rollout of a predictive policing model? a predictive policing model would be intended to predict crime but the data may be measuring arrests, and any model using it would then be modeling arrests instead of crime depending on existing police practices and any biases that exist in how people are arrested, the biases of these data would likely lead police to put more attention on areas with more arrests, leading to more arrests in those high-arrest areas This is an example of a positive feedback loop, because the more the model is used, the more biased the data becomes, the more biased the model becomes | . | . | . | . | Do we always have to use 224×224-pixel images with the cat recognition model? Not anymore, that is just the standard size for historical reasons old, pre-trained models required exactly 224x224 pixels | . | Increased picture size likely leads to higher accuracy since it will be able to focus on more details, but at the price of speed and memory consumption | . | What is the difference between classification and regression? it’s a difference in prediction: classification predicts a discrete class from available options while regression predicts a value from a continuous scale | . | What is a validation set? What is a test set? Why do we need them? a validation test is the portion of data not used for training used to validate the accuracy of the model during training and assess any overfitting but there’s a chance we overfit the validation data as well because the human modeler is also apart of the process when picking hyper parameters | the test set is used for the final evaluation of the model to ensure the model will generalize | . | . | . | . | if you don’t have much data, a validation set may be enough | . | What will fastai do if you don’t provide a validation set? automatically create one (can be specified with valid_pct = X) | . | Can we always use a random sample for a validation set? Why or why not? Not always. While a random sample may be a good way of obtaining a validation set that is representative of your population, we always need to be mindful of the problem at hand. For example, when working with time series data, it would probably be cheating to make predictions about an earlier point in time, so our validation set would need to be the newest data you have | . | What is overfitting? Provide an example. Overfitting is the issue of a model learning too much about the specific inputs you gave it instead of all possible inputs that it could be given for the problem at hand. I.e., the model does not generalize to unseen data | especially important for neural networks because they can potentially memorize the dataset | . | . | What is a metric? How does it differ from “loss”? a metric is a function that measures the quality of the model’s predictions using the validation set Ex. error rate | . | this is similar to loss, which is also a measure of | loss is meant to be used by the optimization mechanism while a metric is used by the human modeler | . | How can pre-trained models help? pertained models are models that have already been trained on data for similar problems | useful in image detection because they have already learned | when it works out, using them could save time/$ and you’d need less data | transfer learning refers to the usage of a pre-trained model | . | What is the “head” of a model? When using a pre-trained model, the latter layers of that model are usually customized for the original problem. But we’ll need to replace those for the new problem at hand. These new layers are referred to as the “head” of the model | . | What kinds of features do the early layers of a CNN find? How about the later layers? Earlier layers learn simple features like diagonal, horizontal, and vertical edges | Latter layers learn more advanced features like car wheels, flower petals, and even outlines of animals | . | Are image models only useful for photos? No, because many data can be creatively represented as images | . | What is an “architecture”? refers to the kind of model we want to make CNN vs RNN vs GAN vs others | . | only describes a template for a mathematical function doesn’t actually do anything until we provide values for the parameters it contains | . | . | What is segmentation? pixelwise classification/labeling of what part of the picture each pixel represents | . | What is y_range used for? When do we need it? used to limit the range of values that could be predicted | like when rating movies on a 1-10 scale | . | What are “hyper-parameters”? parameters for our parameters | determine how our model is being trained | Ex: how long do we train for, what our learning rate is | . | What’s the best way to avoid failures when using AI in an organisation? Make sure a training, validation, and testing set is defined properly in order to evaluate the model in an appropriate manner | Try out a simple baseline, which future models should hopefully beat. Or even this simple baseline may be enough in some cases | Make sure everyone agrees about what that point is that point should be your metric | | |",
            "url": "https://lelarson.github.io/blog/2021/03/29/Deep-Learning-For-Coders-Ch1-Questionairre.html",
            "relUrl": "/2021/03/29/Deep-Learning-For-Coders-Ch1-Questionairre.html",
            "date": " • Mar 29, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://lelarson.github.io/blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://lelarson.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://lelarson.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}